\documentclass[10pt, oneside]{report} 
\usepackage{amsmath, amsthm, amssymb, calrsfs, wasysym, verbatim, bbm, color, graphics, geometry}

\usepackage{titlesec}
\setcounter{secnumdepth}{3}

\geometry{tmargin=.75in, bmargin=.75in, lmargin=.75in, rmargin = .75in}  

\newcommand{\O}{\mathbb{O}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\Cdot}{\boldsymbol{\cdot}}

\newtheorem{thm}{Theorem}
\newtheorem{defn}{Definition}
\newtheorem{conv}{Convention}
\newtheorem{rem}{Remark}
\newtheorem{lem}{Lemma}
\newtheorem{cor}{Corollary}


\title{Diffusion Notes}
\author{Nicholas Leland}
\date{October 2024}

\begin{document}

\maketitle
\tableofcontents

\vspace{.25in}

\chapter{Step by Step Diffusion: An Elementary Tutorial}
The first source that we will be taking a look at is \textbf{Step by Step Diffusion: An Elementary Tutorial}.  This is meant to pose as an introductory course to the concept of Diffusion, and should help us gain a general understanding of the topic.  

\section{Fundamentals of Diffusion}

\subsection{Gaussian Diffusion}

Gaussian diffusion is the act of taking images that have had noise applied to them, \textit{denoising} the image in order to gain a deeper understanding of the framework that the image is built on. 
\\
\\

We will begin by exploring how we inject our images with noise.  

\begin{defn}
    the {\em Forward Process} can be described as follows: 
    \[
        x_{t+1} := x_1 + n_t,   n_t ~ \mathscr{N}(0, \sigma^2)
    \] 
\end{defn}

Essentially, we are creating a target distribution $p*$ that is generated using a data set we have identified.  Then, using this formula, we generate multiple random variables $(x_0, x_1, x_2, \ldots, x_t$.  With these random variables (in our case, images), we can identify that we slowly begin to approach the \textbf{Gaussian Distribution}, therefore, we can sample the Gaussian rather then our originally defined $p*$ distribution.
\\
\\

We can evaluate the two distributions using a formula known as KL Divergence.

\begin{defn}
    The \textbf{Kullback-Leibler (KL) divergence} between two distributions $P$ and $Q$ is defined as:
    \[
        D_{KL}(P||\mathscr{Q}) = \sum_{x} P(x) log \frac{P(x)}{Q(x)}
    .\] 
    or for a continuous distribution:
    \[
        D_{KL}(P||Q) = \int_{-\infty}^{\infty}  P(X) log \frac{P(x)}{Q(x)} 
    .\] 
    \begin{itemize}
        \item $P(x)$ is the true probability distribution
        \item $\mathcal{Q}(x)$ is the approximating (or target) probability distribution
        \item $D_{KL}(P||Q)$ is the KL Divergence which is non-negative and measures how much information is lost when $Q$ is used to approximate $P$.
    \end{itemize}
\end{defn}

So would we be utilizing Continuous or Discrete variables? You might think initially that due to the format of image files given as:
\[
    P_{ij} \subset [0, 255]^3   for i = 1, \ldots, W and j=1, \ldots, H 
.\] 
Realistically though, our model will think within the space of 0-1 instances which we will then convert into our discrete space.  We will find later on that this quantization is actually quite a problematic idea with images.

It might be important to have these definition's on hand as well, mainly just as a refresher.

\begin{defn}
    Probability Density Function
    \[
    P(x) = \frac{1}{(2\pi)\frac{d}{2}|\sum|\frac{1}{2}}exp(-\frac{1}{2}(x - \mu)^T \sum^{-1}(x - \mu)) 
    .\] 
    where:
    \begin{itemize}
        \item $x$ is a $d$-dimensional random vector.
        \item $\mu$ is the mean vector
        \item $\sum$ is the covariance matrix.
    \end{itemize}
\end{defn}

\begin{defn}
    Covariance Matrix
    \[
        Cov(X, Y) = \E[(X - \E[X])(Y - \E[Y])]
    .\] 
    where:
    \begin{itemize}
        \item $\E[X].$ is the expected value (mean) of $X$.
        \item $\E[Y].$ is the expected value (mean) of $Y$.
    \end{itemize}
\end{defn}

Now that we have initial definitions out of the way, let's reevaluate our problem.  We have an image, we want to define some way to reconstruct an image of that nature.  Our sub problem is essentially:
\\
\\

\textit{"Given a sample marginally distributed as $p_t$, introduce a sample marginally distributed as $p_{t-1}$ "}
\\
\\

Now that we have established our noisy image, the goal is to create a model which can identify features and effectively denoise our image.  This method is known as a \textbf{reverse sampler}.
\\
\\

We would effectively move through each position until indefinitely reaching our original, target distribution $(p_0 = p^*)$.  This leads us to the primary idea behind diffusion, rather then learning how to go from a noised image back in one step (more in line to how a VAE functions), we instead go through multiple steps and learn the process behind each.
\\
\\

We can construct reverse samplers in many different ways, the \textbf{DDPM Sampler} is known as the standard diffusion sampler.  This uses a very simple strategy, at a time $t$, given the input $z$, where $z$ is a sample from $p_t$, output a sample from the conditional distribution.
\[
    p(x_{t-1}|x_t = z)
.\] 

This seems very simple but realistically there is much more to the entire process.  If we were to have a model for every single step of $x_t$, this would be quite a large process.  The key is identifying the \textit{per step noise} or  $\sigma$.
\\
\\

If this amount of noise that we are adding per step is small enough, the distribution becomes simple.  

\begin{defn}
    \textbf{Diffusion Reverse Process}: For small $\sigma$, the Gaussian diffusion process defined in (1), the conditional distribution $p(x_{t-1}|x_t$ is itself close to Gaussian.  That is, for all the times $t$ and conditioning $z \subset \R^d$, there exists some mean parameter $\mu \subset \R^d$ such that:
 \[
p(x_{t-1}|x_t = z) \approx \mathcal{N}(x_{t-1} : \mu, \sigma^2
.\] 
There is a lot going on here, let's talk about it in a bit more detail.  Essentially speaking, if we have the distribution that we are trying to understand, by targeting a certain point and minimizing our $\sigma$ value, the distribution approaches that of the Gaussian at a much more aggressive rate.  This allows us to have one missing value to focus on, the mean $(\mu)$.

\end{defn}

This is a really important statement, so let's go through this one more time.  

\begin{itemize}
    \item For a given time $t$ and a conditioning value $x_t$, learning the mean of $p(x_{t-1}|x_t$ is sufficient to learn the full conditional distribution $p(x_{t-1}|x_t$.
    \item Now that we know we must just determine the mean (\mu), we can just utilize a simple tool like \textbf{simple linear regression}! 
    \item to begin we have a joint distribution $(x_{t-1}, x_t)$
    \item Our goal is to estimate $\E[x_{t-1}, x_t]$
\end{itemize}

\begin{defn}
    \textbf{Standard Regression Loss} : Remember, for any distribution over $(x, y)$, we have: 
\[
\begin{aligned}
    &\arg \min_f \E\left[ || f(x) - y ||^2 \right] = \E[y|x] \\
    &\mu_{t-1}(z) := \E[x_{t-1}|x_t = z] \\
    &\mu_{t-1} = \arg \min_{f : \R^d \rightarrow \R^d} \E_{x_t, x_{t-1}}  || f(x_t) - x_{t-1} ||_2^2 \\
    &\arg \min_{f : \R^d \rightarrow \R^{dxd`}} \E_{x_t, x_{t-1}, \mathcal{n}_t}  || f(x_{t-1} + \mathcal{n}_t) - x_{t-1}||^2_2 
\end{aligned}
\]
\end{defn}

Essentially, we are optimizing the $\mu $ for the mini\mum difference between our given distribution and the noise that is generated on the image.  $x_0$ is from our target distribution $p^*$. When target $p^*$ is a distribution on images, then the corresponding regression problem is exactly an \textbf{image denoising objective}.  This objective can then be approached with deep learning techniques such as traditional CNN's.  
\\
\\
Through this process we have taken our goal of \textbf{learning to sample from an arbitrary distribution} to the standard \textbf{problem of regression}.

\\
\\

\subsection{Diffusions in the Abstract}
Forget about the Gaussian now. Let's break down our \textit{diffusion-like generative model}. 
\begin{itemize}
    \item Start with a target distribution ($p^*$)
    \item Pick a base distribution ($q(x)$) that is easy to sample from (Standard Gaussian or i.i.d bits)
    \item Construct a sequence of distributions which interpolate between the target $p^*$ and the base distribution $q$.  We now have a set of distributions $p_0, p_1, p_2, \ldots, p_t$. 
    \item With these distributions, $p_0 = p^*$ (Our Target), $p_t = q$ (base distribution) and the rest of the distributions, $p_t-1, pt$, are marginally close to one another.  The smaller steps the more accurately we can assume the base distribution.
    \item Then we learn a \textit{reverse sampler} to take our $p_t$ distributions and transform them into $p_{t-1}$.  This is how we train the model, or our \textit{learning step}.
\end{itemize}

\begin{defn}
    \textbf{Reverse Sampler} Given a sequence of marginal distributions $p_t$, a reverse sampler for step $t$ is a potentially stochastic function $F_t$ such that if $x_t ~ p_t$, then the marginal distribution of $F_t(x_t)$ is exactly $p_{t-1}$:
    \[
        {F_t(z) : z ~ p_t} \equiv p_{t-1}
    \] 
\end{defn}

Remember, stochastic functions are just functions that have an unpredictable outcome, which is entirely valid based on the assumption of how noise is added.
\\
\\
There are many possible reverse samplers that are available, some are even \textit{deterministic}, or include no randomness. In some cases, it is possible to instantiate in a discrete setting where the distribution $p^*$ is over a finite set and there are corresponding "interpolating distributions" and reverse samplers. 
\\
\\
We will be evaluating three very popular reverse samplers here:
\begin{itemize}
    \item The DDPM sampler
    \item The DDIM Sampler (More deterministic
    \item The Family of \textit{flow-matching models}, a generalization of DDIM
\end{itemize}

\subsection{Discretization}
Very quickly, we run into the problem regarding dealing with discrete values (float vs int). The process of taking a function that is normally a continuous function and transferring that into one that is discrete is known as \textbf{discretization}. The goal is to reduce the amount of error down to a set \textit{negligible amount} by the end of the process.  
\\
\\
Currently we have explained the process of de-noising an image as finding a step value ($p_{t-1}$ where the value is \textit{extremely small}, therefore we can draw the same assumptions about the baseline distribution that we are using.  We run into a problem when evaluating how small this step ($p_t, p_{t-1}$ actually ends up being.  
\\
\\
As a refresher, we have a time-evolving function, $p(x, t)$, which starts from the target distribution ($p_0$ at time $t = 0$ ) and ends at the noisy distribution ($p_t$ at time $t = 1$).  It is important to note, this is not a traditional function but rather the current status of our distribution at the set points ($x$ and $t$).  To reiterate, $p(t_0, x)$ is our original distribution (our clean image) and $p(t_1, x)$ is our distribution where we represent our target distribution.
 \[
p(x, k\Delta t) = p_k(x), where \Delta t = \frac{1}{T}
.\] 
Here, $T$ is the \textit{fineness} of the steps that we are taking.  The more steps (and presumably the smaller the $\sigma$ value), the closer the image is from step to step.
\\
\\
We run into a very interesting problem now. We need to ensure that the variance of the final distribution $p_t$ is \textit{independent of the number discretization steps}.  To ensure that this is a reality, we need to be more specific about our incremental variances. 
\\
\\
Let's look at the following given fact.  If $x_k = x_{k-1} + \mathcal{N}(0, \sigma^2)$ then $x_t \sim \mathcal{N}(x_0, T\sigma^2)$
\\
\\
Essentially, because we are pulling from our target distribution so many times, normally, this would cause an overlap to occur, which in turn would aggressively scale our variance.  This would result in our variance scaling at a factor of $T \cdot \sigma^2$.  This would be quite problematic as the stacking variance would skew our distribution.  To accommodate for this, we will instead by scaling the variance by the number of steps. 
\[
Total\ Variance = T \cdot (\sigma^2 \cdot \Delta t) = T \cdot (\sigma^2 \cdot \frac{1}{T}) = \sigma^2_2
.\] 
Remember, $\Delta t =  \frac{1}{T}$ is the amount that we will be scaling by.  With this fact, we will be choosing. \[
    \sigma = sigma_q\sqrt{\Delta t}
.\] where $\sigma^2_q$ is the \textit{desired terminal variance}.  This concept of \sqrt{\Delta t} scaling will be very important, and it's the baseline that SDE (Stochastic Differential Equation) formulation will build on later. By choosing $\sigma^2_q$ with the desired terminal variance, we ensure that the variance of $P_t$ is always $\sigma^2_q$ regardless of our $T$.
\\
\\
At this point, we will be taking a temporary pause with this section and instead be jumping to the next chapter of these notes.  This will build up the fundamentals regarding Stochastic Differential Equations, which will be very relative for the upcoming diffusion notes. 


\chapter{Stochastic Differential Equations}
\section{Differential Equations}
This section will be primarily reviewing general differential equations and their fundamentals.  We will be going over the baselines with some basic videos, and then diving into more traditional mathematical approaches after that.  
\subsection{Differential Equations, a tourist's guide}
The first resource that we will be evaluating is the 3Blue1Brown video series regarding differential equations. This is avalible here: https://www.youtube.com/watch?v=p_di4Zn4wz4&list=PLZHQObOWTQDNPOjrT6KVlfJuKtYTftqH6

Differential Equations are essentially a function in which it is easier to document the change in numbers rather then the direct values.  

Why they grow or shrink over why it is one value over another.

Differential equations are one of two:
Ordinary Differential Equations (one input) or Partial Differential Equations (multiple inputs)
\begin{itemize}
    \item Ordinary Differential Equations or \textbf{ODE}'s, are typically involving time.  This is very commonly associated with physics calculations.  
    \item Partial Differential Equations or \textbf{PDE}'s, deal with multiple inputs like a temperature at points in a solid body or the velocity of a fluid at different points in space. 
\end{itemize}
Say we have an item falling.  Based on earths gravity, our object is falling at a rate of $-9.8 \frac{\frac{m}{s}}{s}$.  This itself can be expressed as a differential equation, where it's derivative, gives the velocity, and the second derivative as the acceleration.  
We turn this into a differential equation problem when we begin to ask the reverse question.  If we look at a generalized problem, we find that as we work through this problem backwards, we begin to introduce additional constants that are free to change.  If we want to find the function which has an acceleration of 9.8, we are looking for a function with $-g$ as its derivative.  This ends up introducing a $t$ constant, which we know as time.  If we do the same with our new function, looking for the original function given our acceleration and time constant, we now introduce an additional constant, one that changes the starting position. 
There can be many functions with each derivative, which is why we now need to clarify given the new constants.  
Again, if my acceleration is a second or d er derivative, -9.8.  When I am trying to find the inverse of the derivative, there are many functions that might end up with this derivative, we need to isolate with the additional time position. 

What if the forces depend on the location of the body? At this rate, we have an interchangeable exchange between a potential location and the resulting differential variable.  

Often in differential equations, the puzzles you face involve finding a derivative or higher order derivative which is defined interms of the function itself. 

\section{18.S096 Lecture 21: Stochastic Differential Equations}
This next section of notes will be directly from an MiT lecture avalible on youtube at https://www.youtube.com/watch?v=qdbkvD4N-us.  This is primarily from the background of a FinTech domain, but should also go through some aspects that will be applicable for diffusion before we jump into the next section.
\\
\\
Say we are given a Differential Equation.  
\[
    dX = \mu(t, X(t))dt + \sigma(t, X(t) dB(t)
.\] 
Our goal is to find a stochastic process $X(t)$ that satisfies a given function.  

\end{document}


